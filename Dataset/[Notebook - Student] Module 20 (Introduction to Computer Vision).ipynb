{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision\n",
    "\n",
    "\n",
    "To navigate up and down, you can use the up and down arrow keys on your keyboard<br />\n",
    "To execute code in this workbook, select the code block and press **Shift+Enter** <br />\n",
    "To edit the code block, press enter. \n",
    "\n",
    "#### The codes in this workbook are cumulative. (Variables defined continue to be available until the notebook is closed) <br />\n",
    "#### So do start from the top and work your way down to avoid unexpected results!\n",
    "\n",
    "\n",
    "For more help on using Jupyter Notebook, you can click on Help > User Interface Tour in the menu above, <br />\n",
    "or visit https://jupyter-notebook.readthedocs.io/en/stable/ui_components.html\n",
    "\n",
    "Experiment and test out your ideas, for that is one of the fastest ways to learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How do computers see?\n",
    "When you played the icebreaker earlier, your classmate could not talk but you could easily identify your classmate based on what was written on his/her wristband. You used your eyes to see, and your brain processed that information. \n",
    "\n",
    "Can we get a computer to do something similar? \n",
    "<br />\n",
    "Where do we even start?\n",
    "\n",
    "Similar to how we recognized our friends, there are 2 parts.<br />\n",
    "1) Seeing with your eyes<br />\n",
    "2) Making sense of what we see (recognizing your friend, or what he/she wrote or drew on the wristband)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will be using the IntelÂ® Distribution for Python and OpenCV.\n",
    "\n",
    "Another useful Python library will be the Numpy library, which is very useful for quick array manipulations. Images are actually stored as arrays/matrices of pixels, and hence, Numpy would be very useful for helping us to do faster image processing.\n",
    "\n",
    "If you have no prior experience with Python and Numpy, <br />\n",
    "you can get a good introduction online at https://www.datacamp.com/courses/intro-to-python-for-data-science\n",
    "\n",
    "To execute the code block below, select it and press **Shift+Enter**  <br />\n",
    "The results of your execution will be printed directly below the code block. In this case, it will show you your installed version of OpenCV and Python.\n",
    "\n",
    "### Importing your Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have successfully installed OpenCV version 4.5.4-dev\n",
      "Your version of Python is 3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import cv2              #Import the OpenCV Library\n",
    "import numpy as np      #Import the Numpy library\n",
    "import sys\n",
    "\n",
    "print (\"You have successfully installed OpenCV version \"+cv2.__version__)\n",
    "print (\"Your version of Python is \" + sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Seeing. Let's display our first picture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"[Dataset] Module 20 images/image001.png\")   #Load the image file into memory\n",
    "cv2.imshow(\"Image\", img)                  #Display that image\n",
    "\n",
    "cv2.waitKey(0)                            #Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After running the code block above, check out your windows to see if the image has been produced!\n",
    "\n",
    "Let's find out what's the size of this image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 800)\n"
     ]
    }
   ],
   "source": [
    "print (img[:,:,2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You have used OpenCV to read your image and display it on another window. \n",
    "\n",
    "However, we have also learnt in acquire stage that we can use another library to show the image on this Notebook. Do you remember what library is it? \n",
    "\n",
    "### Task 1: Import matplotlib library and display the image on this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\HEFRY ANESTI\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\HEFRY ANESTI\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\HEFRY ANESTI\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:296408)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\HEFRY ANESTI\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\HEFRY ANESTI\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1001414422\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(img[0], img[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is your color correct? If not, remember to use the right command to change the color space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think the computer understands what is in the image at this stage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1b Instead of just a picture, how about using your webcam?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HEFRYA~1\\AppData\\Local\\Temp/ipykernel_12492/1936941679.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m             \u001b[1;31m# Capture frame by frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Press Spacebar to Exit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m              \u001b[1;31m# Display the frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Stop if spacebar is detected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame   \n",
    "    cv2.imshow('Press Spacebar to Exit', frame)              # Display the frame\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "    camera.release()                           # Cleanup after spacebar is detected.\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Did you see yourself on the screen? Are you getting excited with ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Making sense of what we see\n",
    "\n",
    "So we have quickly achieved the first part of seeing. Now the computer needs to make sense of what it sees.\n",
    "\n",
    "Remember Numpy? In OpenCV, images are stored as Numpy Arrays.\n",
    "\n",
    "These arrays have built in methods that you can use to quickly analyze your image.<br />\n",
    "For example, **.shape** would tell you the dimensions of the Numpy array where the image is stored. (height, width, channels)<br />\n",
    "There are also various other advanced array manipulation techniques, but we'll keep it simple for now.\n",
    "\n",
    "By default, there are 3 channels to store the pixel intensities of Blue, Green, and Red. This is the default colour space used by OpenCV.\n",
    "\n",
    "For the image you displayed above, What are the dimensions? What colour is it at different parts of the image? How are colour intensities represented?\n",
    "\n",
    "<img src=\"[Dataset] Module 20 images/image001.png\" alt=\"Drawing\" style=\"width: 400px; border:1px solid; float:left;\"/>\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "Try understanding the image for yourself below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the dimensions of this image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)         #What are the dimensions of this image? \n",
    "                         #What is the width, What is the height, How many channels are there?\n",
    "                         #Hint: Images are represented in Numpy arrays as (height,width,channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the color of the top left corner of the image? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 255   0]\n"
     ]
    }
   ],
   "source": [
    "print(img[0,0])          #What is the color of the top left corner of the image? Notice that array indexing starts from 0\n",
    "                         #Hint: the channels are represented as Blue,Green,Red by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Find out the color of the top right corner of the image.\n",
    "What is the color of the top right corner of the image? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    " # atau 799 #Hint: Notice that the rightmost pixel is 799 not 800. Numpy array indexing starts from 0.\n",
    "\n",
    "image = img[0, 799]\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Find out the color of the middle of the image.\n",
    "What is the color in the middle of the image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "img[0, 300]\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think the computer understands that there are squares and circles in the image at this stage?<br />\n",
    "Or is it only aware that there are rows and rows of pixel intensities that seem to have values from 0 to 255?\n",
    "\n",
    "Yes, by the way, the pixel intensities from 0 to 255 are basically how much of a particular colour is present. <br />\n",
    "0 means that the intensity is 0 (basically dark), while 255 means that it is full of that colour.\n",
    "\n",
    "So, (0,0,0) would be black, and (255,255,255) would be white. How would you represent blue, green or red?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Processing\n",
    "\n",
    "We have discovered that a computer sees images as arrays of pixel intensities, <br />\n",
    "and it is up to the computer vision developer (you) to make sense of that image.\n",
    "\n",
    "Let us dig into some of the more common image processing techniques that you may find useful. <br />\n",
    "For a more detailed discovery, some links will be provided at the end for you to dig even deeper.\n",
    "\n",
    "Oh wait, before that, can you think of some examples of how computer vision is used in the real world today? You will be discussing that as a class later so you might want to make some notes as you think."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Color Spaces/ organization of colors\n",
    "\n",
    "We have been using the Blue, Green and Red color space on the images earlier. \n",
    "\n",
    "What if we didn't need all the colors and just needed to know how light or dark an image was? We can convert the photo into grayscale. \n",
    "\n",
    "Do you remember how are greyscale images represented in Numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"[Dataset] Module 20 images/image001.png\")\n",
    "grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #Convert color from BGR to grayscale\n",
    "cv2.imshow(\"Grey\",grey)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Now show the grayscale picture on this notebook. \n",
    "Use a new variable (not img)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "cv2.imshow(\"gery\", grey)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: display the grayscale array shape. \n",
    "What number do you expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grey.shape #your code here                    # Are these dimensions different from img.shape earlier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there less memory being used to store the image now that everything is in greyscale? <br />\n",
    "Does this mean that processing this image would potentially be faster since it has 1/3 the size of the original array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Find out the color of the top left corner of the image.\n",
    "What is the color of the top left corner of the image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here          # What is the color of the top left corner of the image? Notice that array indexing starts from 0\n",
    "                                    # How does this compare to your previous finding above?\n",
    "\n",
    "grey[0, 0]\n",
    "grey[300, 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Find out the color of the top right corner of the image.\n",
    "What is the color of the top right corner of the image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here          # What is the color of the top right corner of the image? \n",
    "grey[0, 799]              # How does this compare to your previous finding above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun Fact: Do some colors actually appear darker than others when converted to greyscale? \n",
    "You can read up more about the different color spaces at https://docs.opencv.org/4.0.0/de/d25/imgproc_color_conversions.html\n",
    "\n",
    "We will not be going too deep into the other color spaces, but if you are interested, do read up the link above. And when you have more questions, you can use the Internet to help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Thresholding, Masking and Region of Interest\n",
    "Earlier, we saw how some colours were darker than others. What if we were only interested in a part of the picture that was very dark or very light? Could we filter out just the square on the top right of the screen?\n",
    "\n",
    "**Technique 1: Greyscale Intensity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall that the square on the top right had a pixel intensity of 29\n",
    "# Now everything with a value greater than 29 will become 255 (white)\n",
    "# This means that we are setting a treshold value of 29\n",
    "\n",
    "ret,thresholded = cv2.threshold(grey,29,255,cv2.THRESH_BINARY)  \n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square that we want appears black, while the other parts of the image appears white. We can now focus on this area for further processes. \n",
    "\n",
    "The area we want to focus on is usually called the Region of Interest (ROI)\n",
    "\n",
    "### Task 8: What if you want the text, the circle and the middle and the box at the right to be captured (marked black)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "ret,thresholded = cv2.threshold(grey,76,255,cv2.THRESH_BINARY)  \n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue working with treshold value of 29.\n",
    "\n",
    "Usually, we would want the Regions of Interest (ROI) to be white, and the other areas black instead. Let us try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresholded = cv2.threshold(grey,29,255,cv2.THRESH_BINARY_INV)    #we use cv2.THRESH_BINARY_INV instead of cv2.THRESH_BINARY\n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: What if you want the text, the circle and the middle and the box at the right to be the ROI (marked white)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "ret,thresholded = cv2.threshold(grey,76,255,cv2.THRESH_BINARY_INV)  \n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the use of this? You may ask. \n",
    "\n",
    "Well, thresholding the Region of Interest (ROI) can allow us to use it as a mask to display on the original image.\n",
    "\n",
    "### Mask?\n",
    "**But what is a mask?**\n",
    "\n",
    "Let us take a look at the illustration below:\n",
    "\n",
    "<img src=\"[Dataset] Module 20 images/image001_masking.jpg\" />\n",
    "\n",
    "In the image (in the middle) above, you can see the mask for the blue square on the top right corner. When we apply that mask (image in the middle) to the original image (image on the left), only the blue square is left in the masked image (image on the right).\n",
    "\n",
    "The mask layer helps to highlight the parts of the image that we are interested in. When the mask is applied to the image, only the parts that we are interested in are kept (white regions of the mask), while the remaining parts (black regions) of the image are discarded. \n",
    "\n",
    "Fun Fact: You can also see this concept at work in popular image editing softwares such as Adobe Photoshop, where you can apply \"clipping masks\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresholded = cv2.threshold(grey,29,255,cv2.THRESH_BINARY_INV)  \n",
    "\n",
    "masked = cv2.bitwise_and(img, img, mask = thresholded) \n",
    "cv2.imshow(\"Masked\", masked)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Did you manage to filter the blue square?\n",
    "\n",
    "Ok, time for you to experiment and see what else you would like to threshold. Can you threshold just the Circle in the middle? How would you do that in grayscale layer?\n",
    "\n",
    "Perhaps the grey layer is not the best layer to work with. Remember you have the original image:\n",
    "\n",
    "<img src=\"[Dataset] Module 20 images/image001.png\" alt=\"Drawing\" style=\"width: 400px; border:1px solid; float:left;\"/>\n",
    "<div style=\"clear: both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technique 2: Colours.**<br />\n",
    "Remember that images are numpy arrays? And Numpy arrays can be filtered easily with advanced filters.\n",
    "\n",
    "To make our lives easier, we may want to change the white in the background to black instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = img.copy()                         # The masked image we are going to create. Initialize with a copy of initial image.\n",
    "(b,g,r) = cv2.split(img)                  # Split the BGR images to single planes so that we can work on the channels separately\n",
    "mask[(b==255)&(g==255)&(r==255)] = 0      # Change white background (when BGR channels are all 255) to 0 (black).\n",
    "\n",
    "cv2.imshow(\"Mask\",mask)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore what the different layers of the mask looks like. They are the layers 0, 1 and 2 respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Blue Mask\",mask[:,:,0])       # Notice how the words are blue also\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Green Mask\",mask[:,:,1])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Red Mask\",mask[:,:,2])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technique 3: Quick Numpy Array Manipulation based on position**\n",
    "\n",
    "There are some artifacts around the words for this green layer. Can we clean it up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[300:,:,1]=0                          # Remember that the image is a matrix. Let's wipe the bottom half to black (0)\n",
    "cv2.imshow(\"Green Mask\",mask[:,:,1])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not remember the size of your image, which command can you use to find out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if there are artifacts around the words for the red layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Red Mask\",mask[:,:,2])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some artifacts around the words for this red layer also. Can we clean it up?\n",
    "\n",
    "### Task 10: Clean up the artifacts around the words for this red layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[400:,:,0]=0                          # Remember that the image is a matrix. Let's wipe the bottom half to black (0)\n",
    "cv2.imshow(\"Green Mask\",mask[:,:,2])\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply get the objects based on colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 2 is the red layer. Rememeber (B,G,R)\n",
    "masked = cv2.bitwise_and(img,img,mask=mask[:,:,2])\n",
    "cv2.imshow(\"Circle\",masked)                   \n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 1 is the green layer. Rememeber (B,G,R)\n",
    "masked = cv2.bitwise_and(img,img,mask=mask[:,:,1])\n",
    "cv2.imshow(\"Left Green Rectangle\",masked)\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 0 is the blue layer. Rememeber (B,G,R)\n",
    "masked = cv2.bitwise_and(img,img,mask=mask[:,:,0])\n",
    "cv2.imshow(\"Right Blue Rectangle\",masked)\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the words are also appearing not just the rectangle? This is because the words are also _blue!_\n",
    "\n",
    "If you don't want the words to appear, you can \"wipe\" it away:\n",
    "\n",
    "### Task 11: Wipe the words away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have spent quite a bit of time on masking, thresholding and regions of interest. There are different approaches you can use, whether it is by colour, or by pixel intensity, or by manipulating the Numpy Array (e.g. for accessing and modifying parts of the image). Do take some time to practice these techniques and try it on different images.\n",
    "\n",
    "In computer vision, and in life, there are often multiple ways that you can reach the same objective. Can you think of more efficient ways to get your Region of Interest? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Geometric Transformations. Resizing and Cropping\n",
    "\n",
    "Moving on, perhaps the image is too big or too small, how might we resize it?\n",
    "\n",
    "### Task 12: Make the 800x600 image into a 400x300 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the resize function can also be used to stretch the image, if you use a different aspect ratio.\n",
    "\n",
    "### Task 13: Stretch the 800x600 image into a 200x300 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping\n",
    "\n",
    "### Task 14: Crop to obtain the top half of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 15: Crop to obtain the right side of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play around with it. Cropping to a Region of Interest would be more useful. Let's move on to another very useful method for extracting a Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Contour Detection\n",
    "\n",
    "This is what is commonly used to search for regions of interest, typically using a thresholded mask. \n",
    "\n",
    "**But what is a contour?**\n",
    "\n",
    "You can think of contours as a [curve drawn along a boundary](https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html). \n",
    "\n",
    "To simplify this, think of all the black and white masks. There will be boundaries, sharp changes in color. Contours is a curve drawn along this boundary. \n",
    "\n",
    "Contour detection basically finds and returns these different groups as contours.\n",
    "\n",
    "To illustrate, how many white color regions do you think are there in the image below?\n",
    "\n",
    "<img src=\"images/image001_3contours.png\" style=\"width:400px; float:left;\" />\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "Did you guess that there are 3 contours detected? Let us try to load that image and draw the contour outlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 contours!\n"
     ]
    }
   ],
   "source": [
    "greytest = cv2.imread(\"[Dataset] Module 20 images/image001_3contours.png\",0)    # Load that image\n",
    "contouroutlines = np.zeros(greytest.shape,dtype=\"uint8\")    # Create a blank canvas for drawing detected contours\n",
    "\n",
    "# Let's find the contours! https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga17ed9f5d79ae97bd4c7cf18403e1689a\n",
    "(cnts,_) = cv2.findContours(greytest, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for (i, c) in enumerate(cnts):    \n",
    "    cv2.drawContours(contouroutlines, [c], -1, 255, 1)  # For each contour, draw just the outline of the contours\n",
    "                                                        # https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html#ga746c0625f1781f1ffc9056259103edbc\n",
    "cv2.imshow(\"Contour Outlines\",contouroutlines)          # Display the results\n",
    "cv2.waitKey(0)                                          # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")         # Print out the number of contours detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a simple example with just 3 contours. \n",
    "\n",
    "How many contours would you expect to find on our thresholded original image?\n",
    "\n",
    "<img src=\"[Dataset] Module 20 images/image001_allcontours.png\" style=\"width:400px; float:left;\" />\n",
    "<div style=\"clear:both;\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create the image using tresholding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#We apply a threshold\n",
    "(T, thresholded) = cv2.threshold(grey, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will find out the contour. How many do you think it will be? Look at the picture carefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 78 contours!\n"
     ]
    }
   ],
   "source": [
    "# Let's find the contours!\n",
    "(cnts,_) = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "mask = np.zeros(img.shape,dtype=\"uint8\")  # Create a canvas for drawing detected contours\n",
    "for (i, c) in enumerate(cnts):    \n",
    "    cv2.drawContours(mask, [c], -1, (0,255,0), 1) \n",
    "    \n",
    "cv2.imshow(\"Mask\",mask)  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are there 78 contours? That is because of the line of texts. \n",
    "\n",
    "Let us try to label the contours for us to visualize what is actually being counted.\n",
    "\n",
    "Below, you will see how each letter tends to forms 1 contour. But notice how some letters like \"i\" is actually counted as 2 contours since the top of the \"i\" and the bottom of the \"i\" are not connected. Similarly for the exclamation mark.\n",
    "\n",
    "The code below seems a little longer because code has been added for the annotations. You will understand the code better when you visit section 2.5 a little further below. In the meantime, do not worry about the code. Just run the code and see how the contours are counted. Take note of the red bounding boxes which have been drawn around each \"contour\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 78 contours!\n"
     ]
    }
   ],
   "source": [
    "grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#We apply a threshold\n",
    "(T, thresholded) = cv2.threshold(grey, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "# Let's find the contours!\n",
    "(cnts,_) = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = sorted(cnts, key=lambda cnts: cv2.boundingRect(cnts)[1])  #sort contours from top to bottom.\n",
    "\n",
    "mask = cv2.merge([thresholded,thresholded,thresholded])  # Create a canvas for drawing detected contours\n",
    "for (i, c) in enumerate(cnts):   #https://docs.opencv.org/3.1.0/dd/d49/tutorial_py_contour_features.html  \n",
    "    #cv2.drawContours(mask, [c], -1, (255,255,255), -1) \n",
    "    (x, y, w, h) = cv2.boundingRect(c)                   # Get the x,y coordinates of the contour's bounding box \n",
    "    cv2.rectangle(mask, (x,y), (x+w,y+h), (0,0,255))     # Draw the bounding boxes in red\n",
    "\n",
    "    cv2.putText(mask, \"\"+str(i+1), (x,y+28), cv2.FONT_HERSHEY_SIMPLEX, 0.25, (0,255,0), 1)\n",
    "    \n",
    "cv2.imshow(\"Mask\",mask)  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to find out more about contours? You can visit https://docs.opencv.org/3.3.1/d4/d73/tutorial_py_contours_begin.html to dig deeper. As always, do continue searching on the Internet because there is a treasure trove of information out there, and it will be very useful as you go deeper!\n",
    "\n",
    "Tip: In the above examples, we used cv2.RETR_EXTERNAL to get the external contours. There are also other options that you can specify to get different types of contours. For example, cv2.RETR_LIST will list all contours and not just the external contours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Contours as Image Masks**\n",
    "\n",
    "Remember we talked about image masks earlier? The contours can be used to create masks too! \n",
    "\n",
    "Set the last parameter for the drawContour function to -1 to create a fill (instead of an outline), and use it as a mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T, thresholded) = cv2.threshold(grey, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "thresholded[410:,:]=0                     # Shortcut to remove the text since it is on the bottom half of the image!\n",
    "#cv2.imshow(\"Thresholded\",thresholded)\n",
    "\n",
    "#How many contours do you think there are?\n",
    "(cnts,_) = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "mask = np.zeros(thresholded.shape,dtype=\"uint8\")\n",
    "for (i, c) in enumerate(cnts):    \n",
    "    cv2.drawContours(mask, [c], -1, 255, -1)  #the last parameter defines the outline thickness. -1 will fill the contour\n",
    "    \n",
    "cv2.imshow(\"Mask\",mask)\n",
    "cv2.imshow(\"Masked Image\",cv2.bitwise_and(img,img,mask=mask))  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you find it easier than manually thresholding each colour?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Drawing Lines and Writing Texts\n",
    "\n",
    "We actually did a bit of this in the contour exercise above, using a method called drawContour. Let us see how we can add lines and words into images, since we may want to annotate our images. Let's revisit the example in 2.4 and add labels to our contours!\n",
    "\n",
    "Only the 3 lines that have changed are commented below. The other lines of code as similar to the example in 2.4 and you can refer to that example to recap what those lines of code do.\n",
    "\n",
    "First, we get the bounding box for each contour, draw a rectangle around it, and then add the text to label each contour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greytest = cv2.imread(\"[Dataset] Module 20 images/image001_3contours.png\",0)\n",
    "contouroutlines = np.zeros(greytest.shape,dtype=\"uint8\")\n",
    "\n",
    "(cnts,_) = cv2.findContours(greytest, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for (i, c) in enumerate(cnts):    \n",
    "    cv2.drawContours(contouroutlines, [c], -1, 255, 1)\n",
    "\n",
    "    # GET BOUNDING BOX OF EACH CONTOUR\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    \n",
    "    # DRAW A RECTANGLE AROUND EACH CONTOUR (I.E. DRAW THE BOUNDING BOX)\n",
    "    cv2.rectangle(contouroutlines, (x, y), (x+w, y+h), (255,255,0), 2) \n",
    "    \n",
    "    # ADD THE TEXT \"COUNTOUR <>\" TO EACH CONTOUR\n",
    "    cv2.putText(contouroutlines, \"Contour \"+str(i+1), (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "    \n",
    "cv2.imshow(\"Contour Outlines\",contouroutlines)          \n",
    "cv2.waitKey(0)                                          \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"There are \"+str(len(cnts))+\" contours!\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details on writing text on screen, and drawing shapes such as rectangles and circles, you can visit https://docs.opencv.org/4.0.0/dc/da5/tutorial_py_drawing_functions.html\n",
    "\n",
    "If you later create applications for object detection, you can use this method to annotate what you actually detect. Or you could also create your own art work and images using just code! \n",
    "\n",
    "Let's try to draw something from scratch:\n",
    "\n",
    "**ACCESS DENIED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty canvas (height,width,channels) - In this case: 3 colour channels, width 400, and height 300 \n",
    "canvas_accessdenied = np.zeros((600,800,3),dtype=\"uint8\")      \n",
    "\n",
    "# Add a Hollow Rectangle at (x=100,y=230) with the colour (255,255,0), and line thickness 2 \n",
    "cv2.rectangle(canvas_accessdenied, (100, 230), (700, 370), (255,255,0), 2)  \n",
    "\n",
    "# Add your Text at (x=150,y=320) the colour (100,100,255), fint size 2, and line thickness 5 \n",
    "cv2.putText(canvas_accessdenied, \"ACCESS DENIED\", (150,320), cv2.FONT_HERSHEY_SIMPLEX, 2, (100,100,255), 5)\n",
    "\n",
    "cv2.imshow(\"Canvas Access Denied\",canvas_accessdenied)  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about doing one for Access Granted?\n",
    "\n",
    "**ACCESS GRANTED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty canvas (height,width,channels) - In this case: 3 colour channels, width 400, and height 300 \n",
    "canvas_accessgranted = np.zeros((600,800,3),dtype=\"uint8\")      \n",
    "\n",
    "# Add a Hollow Rectangle at (x=100,y=230) with the colour (255,255,0), and line thickness 2 \n",
    "cv2.rectangle(canvas_accessgranted, (100, 230), (700, 370), (255,255,0), 2)  \n",
    "\n",
    "# Add your Text at (x=130,y=320) the colour (255,100,100), fint size 2, and line thickness 5 \n",
    "cv2.putText(canvas_accessgranted, \"ACCESS GRANTED\", (130,320), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,100,100), 5)\n",
    "\n",
    "cv2.imshow(\"Canvas Access Granted\",canvas_accessgranted)  \n",
    "cv2.waitKey(0)                            # Cleanup after any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 16: Create a canvas with 2 boxes. The first box says \"ACCESS GRANTED\", and the second box says \"PLEASE PROCEED\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! \n",
    "\n",
    "## It's time for you to start creating some fun stuff! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wait, anytime you need some help, or if you need to know the syntax of the openCv functions, <br />\n",
    "do look it up at https://docs.opencv.org/4.0.0/d2/d96/tutorial_py_table_of_contents_imgproc.html\n",
    "\n",
    "If you can't find your answers there, there's also a good chance someone else has the answer. Get comfortable using the Internet to find out more!\n",
    "\n",
    "Keep finding solutions to your questions, and keep building good stuff to help with the many challenges out there in the world!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Expand on the video example in section 1.1b, resize the video to 800x600 and display it in greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Use the Python time library, and add a timestamp neatly to the video feed from your webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Code for getting a timestamp. Search online for more options if you need.\n",
    "from datetime import datetime\n",
    "print (datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Using the red and green markers, create different coloured cards. Can you get the computer to recognize whenever a card of a particular colour is presented?\n",
    "\n",
    "Hint: First take a few pictures of the cards, then use simple image processing to analyze their colour patterns. Explore different colour spaces if necessary. Notice how this system might also be rather susceptible to changes in lighting conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Create an application that displays \"ACCESS GRANTED\" whenever you appear (or do something, or show something) in front of the camera \n",
    "\n",
    "Exercise your creativity. The only rule is that you are not allowed to touch the keyboard, and it needs to involve the camera processing the video feed.\n",
    "\n",
    "Challenge. Create something that only grants access to you, and does not grant access to friends who try to pose as you!\n",
    "First you will demonstrate gaining access to the system, 2 times. Then your friend will try to do the same. If your friend does not manage to gain access within 3 minutes, you win!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible techniques: Using a particular color shirt/ carrying a coloured paper. \n",
    "# You are free to explore possibilities and to make it difficult for the opposing team to decipher what they are trying to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5: Watch the video at https://www.youtube.com/watch?v=xyfSUOfFI_E \n",
    "List down ideas of what you may like to create using the powers of Computer Vision.\n",
    "\n",
    "Share some ideas that will help to solve problems which you see in the industry sector you wish to work in"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 6: List down at least 3 examples of Computer Vision applications that you have seen in the real world"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 7: List down some of the limitations of the system that you created in Task 4\n",
    "How do you think it can be improved?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
